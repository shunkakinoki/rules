---
alwaysApply: true
---
---
Source: .ruler/commit-lint.md
---
# Commit Linting Guidelines for AI Agents

This document outlines the commit linting configuration and guidelines that AI agents must follow when committing files to the Kintex project repository.

## Overview

The commit linting system ensures code quality and consistency by automatically running formatting, linting, and commit message validation checks before any commits are made by AI agents. This comprehensive system uses both lefthook pre-commit hooks and commitlint to prevent the introduction of poorly formatted code or improperly formatted commit messages into the repository.

## Installation

### Commitlint Setup

Install commitlint for commit message validation:

```bash
# Install commitlint CLI and conventional config
pnpm add -D @commitlint/cli @commitlint/config-conventional

# Install lefthook for pre-commit hooks
pnpm add -D lefthook

# Initialize lefthook hooks
pnpm run lefthook:install
```

### Required Dependencies

Ensure these packages are installed:
- `@commitlint/cli` - Commit message linting
- `@commitlint/config-conventional` - Conventional commit rules
- `lefthook` - Git hooks management
- `@biomejs/biome` - Code formatting and linting

## Configuration

### Ruler.toml Configuration

The commit linting configuration is defined in `ruler.toml` under the `[commit]` section:

```toml
[commit]
enabled = true
pre_commit_commands = [
  "pnpm run format",    # Format code with Biome
  "pnpm run lint",      # Run linting and checks
  "pnpm run check"      # Run all quality checks
]
```

### Commitlint Configuration

Commit message validation is configured in `.commitlintrc.json`:

```json
{
  "extends": ["@commitlint/config-conventional"],
  "rules": {
    "type-enum": [
      2,
      "always",
      [
        "feat",
        "fix",
        "docs",
        "style",
        "refactor",
        "test",
        "chore",
        "perf",
        "ci",
        "build",
        "revert"
      ]
    ],
    "type-case": [2, "always", "lower"],
    "type-empty": [2, "never"],
    "subject-empty": [2, "never"],
    "subject-full-stop": [2, "never", "."],
    "header-max-length": [2, "always", 72],
    "body-leading-blank": [1, "always"],
    "footer-leading-blank": [1, "always"]
  }
}
```

### Lefthook Configuration

Git hooks are managed through `lefthook.yml` with three main stages:

1. **Pre-commit**: Code formatting and linting
2. **Commit-msg**: Commit message validation
3. **Pre-push**: Comprehensive quality checks

## Pre-commit Commands

### 1. Code Formatting (`pnpm run format`)
- Uses Biome to format all code files
- Ensures consistent indentation, spacing, and line breaks
- Applies project-specific formatting rules

### 2. Linting (`pnpm run lint`)
- Runs comprehensive linting checks
- Validates code quality and style
- Checks for potential bugs and issues

### 3. Quality Checks (`pnpm run check`)
- Runs all automated quality verification
- Ensures ruler rules are applied
- Verifies no uncommitted changes remain

## File Patterns

The linting system targets specific file types to optimize performance:

- **JavaScript/TypeScript**: `*.{js,jsx,ts,tsx}`
- **Configuration Files**: `*.{json,css,md,yml,yaml,toml}`
- **Programming Languages**: `*.py`, `*.rs`, `*.go`, `*.java`
- **Infrastructure**: `Makefile*`, `Dockerfile*`

## Auto-fix Capabilities

The system includes auto-fix commands that attempt to resolve issues automatically:

- **Biome Format**: `pnpm run biome:format`
  - Automatically formats code
  - Fixes spacing and indentation issues

- **Biome Check**: `pnpm run biome:check --write`
  - Auto-fixes linting violations where possible
  - Applies safe corrections

## Agent Responsibilities

When committing files, AI agents must:

1. **Run Pre-commit Checks**: Execute all pre-commit commands before staging files
2. **Review Auto-fixes**: Verify that auto-fixes have been applied correctly
3. **Manual Fixes**: Address any issues that cannot be auto-fixed
4. **Verify Quality**: Ensure all checks pass before committing
5. **Test Changes**: Validate that formatting changes don't break functionality
6. **Solo Authorship**: DO NOT include co-authorship in commit messages - commits should be solo-authored
7. **PR Attribution**: Include AI attribution in PR descriptions, not commit messages

## Pre-commit Hook Detection

AI agents must automatically detect which pre-commit hook system is being used and adapt their behavior accordingly:

### Detection Logic

```bash
# Check for lefthook
if [ -f ".lefthook.yml" ] || [ -f "lefthook.yml" ]; then
  HOOK_SYSTEM="lefthook"
elif [ -f ".pre-commit-config.yaml" ]; then
  HOOK_SYSTEM="pre-commit"
else
  HOOK_SYSTEM="none"
fi
```

#### Fish Detection Logic

```fish
# Check for lefthook (Fish)
set HOOK_SYSTEM none
if test -f .lefthook.yml -o -f lefthook.yml
  set HOOK_SYSTEM lefthook
else if test -f .pre-commit-config.yaml
  set HOOK_SYSTEM pre-commit
end
```

### Lefthook Detection and Usage

**Files to check:**
- `lefthook.yml` (project root)
- `.lefthook.yml` (project root)

**When lefthook is detected:**
- Use lefthook commands for validation
- Respect lefthook configuration settings
- Allow lefthook to handle pre-commit, commit-msg, and pre-push hooks
- Do not run duplicate linting if lefthook is configured

**Lefthook workflow:**
```bash
# Let lefthook handle the hooks automatically
git add <files>
git commit -m "feat: add new feature"

# lefthook will automatically run:
# - pre-commit: formatting and linting
# - commit-msg: commitlint validation
# - pre-push: comprehensive checks
```

### Pre-commit Detection and Usage

**Files to check:**
- `.pre-commit-config.yaml` (project root)

**When pre-commit is detected:**
- Use pre-commit commands for validation
- Respect pre-commit configuration
- Allow pre-commit to manage all hooks
- Do not interfere with pre-commit's hook management

**Pre-commit workflow:**
```bash
# Let pre-commit handle the hooks automatically
git add <files>
git commit -m "feat: add new feature"

# pre-commit will automatically run configured hooks
```

### No Hook System Detected

**When neither system is detected:**
- Fall back to manual validation
- Run linting commands directly
- Validate commit messages manually
- Provide guidance for setting up hooks

**Manual workflow:**
```bash
# Run manual checks
pnpm run lint
pnpm run format
pnpm run check

# Validate commit message format
echo "feat: add new feature" | npx commitlint

# Then commit
git add <files>
git commit -m "feat: add new feature"
```

### Agent Decision Flow

The agent should follow this decision-making process:

```mermaid
graph TD
    A[Agent starts commit process] --> B{Check for lefthook.yml}
    B -->|Found| C[Use lefthook workflow]
    B -->|Not found| D{Check for .pre-commit-config.yaml}
    D -->|Found| E[Use pre-commit workflow]
    D -->|Not found| F[Use manual validation workflow]

    C --> G[Let lefthook handle all hooks]
    E --> H[Let pre-commit handle all hooks]
    F --> I[Run manual checks and validation]

    G --> J[Commit with confidence]
    H --> J
    I --> J
```

### Conflict Resolution

**If both systems are detected:**
- Prioritize lefthook (more project-specific configuration)
- Warn about potential conflicts
- Suggest consolidating to one system

**Detection priority:**
1. lefthook (project-specific, more flexible)
2. pre-commit (standardized, widely adopted)
3. manual validation (fallback)

### Environment-Specific Behavior

**CI/CD Environment:**
- Always use manual validation
- Run all checks explicitly
- Don't rely on git hooks

**Local Development:**
- Use detected hook system
- Fall back to manual if hooks fail
- Provide helpful error messages

### Implementation Example

Here's how an AI agent can implement the detection logic:

```javascript
// Node.js/TypeScript implementation
function detectHookSystem(projectRoot = process.cwd()) {
  const fs = require('fs');
  const path = require('path');

  // Check for lefthook configuration
  const lefthookFiles = ['lefthook.yml', '.lefthook.yml'];
  for (const file of lefthookFiles) {
    if (fs.existsSync(path.join(projectRoot, file))) {
      return {
        system: 'lefthook',
        configFile: file,
        workflow: 'automatic'
      };
    }
  }

  // Check for pre-commit configuration
  const preCommitFile = '.pre-commit-config.yaml';
  if (fs.existsSync(path.join(projectRoot, preCommitFile))) {
    return {
      system: 'pre-commit',
      configFile: preCommitFile,
      workflow: 'automatic'
    };
  }

  // No hook system detected
  return {
    system: 'manual',
    configFile: null,
    workflow: 'manual'
  };
}

// Usage in agent
const hookConfig = detectHookSystem();

switch (hookConfig.system) {
  case 'lefthook':
    console.log(`‚úÖ Lefthook detected (${hookConfig.configFile})`);
    console.log('Using lefthook workflow...');
    break;

  case 'pre-commit':
    console.log(`‚úÖ Pre-commit detected (${hookConfig.configFile})`);
    console.log('Using pre-commit workflow...');
    break;

  default:
    console.log('‚ö†Ô∏è  No hook system detected');
    console.log('Using manual validation workflow...');
    break;
}
```

```python
# Python implementation
import os
from pathlib import Path

def detect_hook_system(project_root: str = ".") -> dict:
    """Detect which pre-commit hook system is being used."""

    # Check for lefthook configuration
    lefthook_files = ['lefthook.yml', '.lefthook.yml']
    for file in lefthook_files:
        if os.path.exists(os.path.join(project_root, file)):
            return {
                'system': 'lefthook',
                'config_file': file,
                'workflow': 'automatic'
            }

    # Check for pre-commit configuration
    pre_commit_file = '.pre-commit-config.yaml'
    if os.path.exists(os.path.join(project_root, pre_commit_file)):
        return {
            'system': 'pre-commit',
            'config_file': pre_commit_file,
            'workflow': 'automatic'
        }

    # No hook system detected
    return {
        'system': 'manual',
        'config_file': None,
        'workflow': 'manual'
    }

# Usage
hook_config = detect_hook_system()

if hook_config['system'] == 'lefthook':
    print(f"‚úÖ Lefthook detected ({hook_config['config_file']})")
    print("Using lefthook workflow...")
elif hook_config['system'] == 'pre-commit':
    print(f"‚úÖ Pre-commit detected ({hook_config['config_file']})")
    print("Using pre-commit workflow...")
else:
    print("‚ö†Ô∏è  No hook system detected")
    print("Using manual validation workflow...")
```

## Integration with Existing Tools

### Lefthook Integration
The commit linting system works alongside existing lefthook pre-commit hooks:

- **Pre-commit Hook**: Runs formatting on relevant files
- **Pre-push Hook**: Runs linting before pushing
- **Commit Lint**: Additional validation for AI agent commits

### Biome Configuration
The system leverages the existing Biome configuration:

```json
{
  "formatter": {
    "enabled": true,
    "formatWithErrors": true,
    "indentStyle": "space"
  },
  "linter": {
    "enabled": true,
    "rules": {
      "recommended": true
    }
  }
}
```

## Error Handling

### Common Issues
- **Formatting Failures**: Check Biome configuration and file permissions
- **Linting Errors**: Review error messages and fix manually if auto-fix fails
- **Command Not Found**: Ensure pnpm and Biome are properly installed

### Troubleshooting Steps
1. Verify Biome installation: `pnpm biome --version`
2. Check configuration: `pnpm run biome:check`
3. Run manual format: `pnpm run biome:format`
4. Review git status after fixes

## Quality Standards

### Code Formatting
- Use 2-space indentation (configured in Biome)
- Consistent line endings and encoding
- Proper spacing around operators and keywords

### Linting Rules
- Follow Biome recommended rules
- No unused variables or imports
- Consistent naming conventions
- Proper error handling

### Commit Message Standards
- Use conventional commit format: `feat:`, `fix:`, `refactor:`, `docs:`, `chore:`
- Keep messages under 72 characters
- Include descriptive details for complex changes

## Best Practices

### For AI Agents
- **Always run linting before committing**
- **Review auto-fixes for correctness**
- **Test functionality after formatting changes**
- **Use descriptive commit messages**
- **Stage files appropriately**
- **Solo-authored commits only** - DO NOT include co-authorship in commit messages
- **PR attribution only** - Include AI attribution in PR descriptions, not commits

### For Development Workflow
- **Regular updates**: Keep Biome and dependencies updated
- **Configuration review**: Regularly audit linting rules
- **Performance monitoring**: Ensure linting doesn't slow down workflow
- **Documentation updates**: Keep this document current with configuration changes

## Commit Message Standards

### Conventional Commit Format

All commit messages must follow the conventional commit format:

```bash
<type>[optional scope]: <description>

[optional body]

[optional footer]
```

### Commit Types

- `feat`: A new feature
- `fix`: A bug fix
- `docs`: Documentation only changes
- `style`: Changes that do not affect the meaning of the code
- `refactor`: A code change that neither fixes a bug nor adds a feature
- `test`: Adding missing tests or correcting existing tests
- `chore`: Changes to the build process or auxiliary tools
- `perf`: A code change that improves performance
- `ci`: Changes to CI configuration files and scripts
- `build`: Changes that affect the build system or external dependencies
- `revert`: Reverts a previous commit

### Examples

```bash
# Feature commit
feat: add user authentication system

# Bug fix with scope
fix(auth): resolve login validation error

# Documentation update
docs: update API documentation for v2.0

# Refactoring with body
refactor: simplify user model validation logic

- Remove redundant validation checks
- Consolidate error handling
- Improve code readability

# Breaking change
feat!: change authentication API interface

BREAKING CHANGE: The authenticate() method now requires email parameter
```

## Example Workflow

```bash
# Make changes to files
git add <files>

# Pre-commit hooks run automatically:
# - Code formatting with Biome
# - Linting and auto-fixes
# - Quality checks

# Create commit with conventional format
git commit -m "feat: add user profile management

- Add profile creation endpoint
- Implement avatar upload functionality
- Add profile validation rules

Closes #123"

# Commit-msg hook validates message format
# Pre-push hooks run comprehensive checks

# Push changes
git push
```

### Troubleshooting Commit Messages

```bash
# If commit message fails validation
git commit --amend
# Edit the message in your editor
# Save and exit

# Or use commit with message flag
git commit -m "fix: correct validation logic"
```

This commit linting system ensures that all AI agent contributions maintain the same high standards of code quality, formatting, and commit message conventions as human developers, creating a consistent and maintainable codebase.

---
Source: .ruler/pr-creation.md
---
# Pull Request Creation Guidelines

When creating pull requests for the Kintex project, follow these automated guidelines to ensure consistency and quality.

## Prerequisites

### GitHub CLI Setup
- Ensure GitHub CLI (`gh`) is installed: `which gh`
- Verify authentication: `gh auth status`
- Token must have `repo` scope for PR creation

### Branch Requirements
- Work on feature branches (not `main`)
- Keep branches focused on single features/fixes
- Use descriptive branch names (e.g., `fix-build-dependencies`, `feat-user-auth`)

## Automated PR Creation Process

### Step 1: Prepare Changes
```bash
# Check current status
git status

# Stage changes
git add <files>

# Commit with descriptive message
git commit -m "feat/fix/refactor: Description of changes"
```

### Step 2: Create Feature Branch
```bash
# Create and switch to new branch
git checkout -b feature-branch-name

# Or switch if branch already exists
git checkout feature-branch-name
```

### Step 3: Push Branch
```bash
# Push branch to remote
git push -u origin feature-branch-name
```

### Step 4: Create PR via CLI
```bash
gh pr create \
  --title "Clear, descriptive title" \
  --body "Detailed description with:
  ## Changes Made
  - Bullet points of what was changed

  ## Technical Details
  - Implementation details
  - Dependencies affected

  ## Testing
  - How changes were tested
  - Pre-commit hooks status

  ü§ñ Generated with Codex CLI
  Co-Authored-By: Codex CLI <noreply@openai.com>" \
  --base main \
  --head feature-branch-name
```

## PR Content Standards

### Title Format
- Use conventional commit format: `feat:`, `fix:`, `refactor:`, `docs:`, `chore:`
- Keep under 72 characters
- Be specific and actionable

### Description Requirements
- **Changes Made**: Bullet list of modifications
- **Technical Details**: Implementation specifics and rationale
- **Testing**: Verification steps and pre-commit status
- **Co-authorship**: Include AI attribution footer

### AI Attribution Guidelines
- **Always use current AI assistant**: Update attribution to match the AI assistant actually used
- **Update when switching assistants**: Modify both the generation notice and co-authorship email
- **Standard format**: `ü§ñ Generated with [AI Name]` followed by `Co-Authored-By: [AI Name] <email>`

#### How to Update AI Attribution:
```bash
# 1. Identify current AI assistant and its company
# Examples:
# - Grok ‚Üí xAI ‚Üí noreply@x.ai
# - Claude ‚Üí Anthropic ‚Üí noreply@anthropic.com
# - GitHub Copilot ‚Üí GitHub ‚Üí noreply@github.com
# - Codex CLI ‚Üí OpenAI ‚Üí noreply@openai.com

# 2. Update all instances in PR templates:
# - ü§ñ Generated with [AI Assistant Name]
# - Co-Authored-By: [AI Assistant Name] <noreply@company-domain>

# 3. Update in these files:
# - .ruler/pr-creation.md (this file)
# - Any other PR template files
# - Documentation examples

# 4. Test the changes:
# - Run a test PR creation to verify attribution appears correctly
# - Ensure the email domain is valid and appropriate
```

### Labels and Reviewers
```bash
# Add labels after creation
gh pr edit <number> --add-label "enhancement,documentation"

# Request reviewers
gh pr edit <number> --add-reviewer username1,username2
```

## Error Handling

### Common Issues
- **Authentication failed**: Run `gh auth login`
- **Branch not found**: Ensure branch is pushed to remote
- **Permission denied**: Check repository access and token scopes

### Troubleshooting Commands
```bash
# Check PR status
gh pr list

# View PR details
gh pr view <number>

# Update PR description
gh pr edit <number> --body "Updated description"
```

## Best Practices

### Commit Guidelines
- **Solo-authored commits only** - DO NOT include co-authorship in commit messages
- Use present tense in commit messages
- Keep commits atomic and focused
- Reference issues when applicable

### PR Size Management
- Keep PRs focused on single concerns
- Split large changes into multiple PRs
- Use draft PRs for work-in-progress
- Request reviews early for complex changes

### Quality Checks
- Ensure all pre-commit hooks pass
- Run tests before creating PR
- Verify code formatting
- Check for breaking changes

## Automated Workflows

### CI/CD Integration
- PRs automatically trigger CI pipelines
- Ensure all checks pass before merging
- Address any failing tests or linting issues

### Merge Strategy
- Use squash merge for clean history
- Delete branches after merge
- Update documentation as needed

## Example PR Creation

```bash
# Complete workflow example
git checkout -b fix-build-dependencies
git add Makefile apps/desktop/turbo.json
git commit -m "fix: Resolve build dependency issues

- Fix shell escaping in Makefile
- Add widget build dependency in turbo.json
- Add combined build target"
git push -u origin fix-build-dependencies

gh pr create \
  --title "Fix build dependencies and shell escaping" \
  --body "This PR fixes build pipeline issues:

## Changes Made:
- Fixed shell escaping in Makefile desktop-prebuild target
- Added turbo.json dependency to ensure widget builds before desktop
- Added combined build target for convenience

## Technical Details:
- Resolves shell variable escaping issue that could cause CI failures
- Ensures proper dependency ordering between components
- Provides unified build command

## Testing:
- Verified build pipeline works correctly
- All pre-commit hooks pass
- Code formatting applied automatically

ü§ñ Generated with Codex CLI
Co-Authored-By: Codex CLI <noreply@openai.com>" \
  --base main \
  --head fix-build-dependencies
```

This process ensures consistent, high-quality PR creation across the Kintex project while maintaining proper attribution and documentation standards.

---
Source: .ruler/pr-labeling.md
---
# GitHub PR Labeling Rules

This rule defines how PR labels are applied automatically. It uses the default labels defined in `labels.ts` and maps Conventional Commit types to GitHub labels.

## Default Labels (source of truth)

Names come from `labels.ts`:

- bug
- documentation
- duplicate
- enhancement
- good first issue
- help wanted
- invalid
- question
- wontfix
- dependabot
- renovate
- dependencies
- automerge

## Label Mapping Rules

- feat ‚Üí enhancement
- fix ‚Üí bug
- docs ‚Üí documentation
- chore(deps), build(deps) ‚Üí dependencies
- PR authored by dependabot ‚Üí dependabot
- PR authored by renovate ‚Üí renovate
- If title contains "[automerge]" or label "automerge" is requested in the description, also add automerge

Notes:
- Only apply one of enhancement/bug/documentation based on the primary Conventional Commit type at the start of the PR title.
- Do not add unrelated labels automatically.

## gh CLI Automation Snippet

Use this non-interactive script to apply labels on current PR. It:
- Detects PR title, author, and branch
- Maps commit type to label
- Adds dependency labels if applicable
- Adds bot-specific labels

```bash
# Requires: gh, jq
set -euo pipefail

# Fetch current PR metadata
TITLE=$(gh pr view --json title --jq .title)
AUTHOR=$(gh pr view --json author --jq .author.login)
BRANCH=$(gh pr view --json headRefName --jq .headRefName)
NUMBER=$(gh pr view --json number --jq .number)

labels=()

# Map Conventional Commit type ‚Üí label
# Expected title formats: "feat: ...", "fix(scope): ...", etc.
TYPE=$(printf '%s' "$TITLE" | sed -E 's/^([a-zA-Z!]+)(\(.+\))?:.*/\1/' | tr 'A-Z' 'a-z' | sed 's/!$//')
case "$TYPE" in
  feat) labels+=("enhancement") ;;
  fix) labels+=("bug") ;;
  docs) labels+=("documentation") ;;
  # Optional: add more mappings if desired
esac

# Dependencies-related labels
if printf '%s' "$TITLE" | grep -qiE '^chore\(deps\)|^build\(deps\)|\bdeps\b|\bdependency\b'; then
  labels+=("dependencies")
fi

# Bot-specific labels
if printf '%s' "$AUTHOR" | grep -qi '^dependabot'; then
  labels+=("dependabot")
fi
if printf '%s' "$AUTHOR" | grep -qi '^renovate'; then
  labels+=("renovate")
fi

# Auto-merge request detection
if printf '%s' "$TITLE" | grep -qi '\[automerge\]'; then
  labels+=("automerge")
fi
if gh pr view --json body --jq .body | grep -qiE '^labels?:.*automerge' ; then
  labels+=("automerge")
fi

# De-duplicate labels
unique_labels=$(printf '%s\n' "${labels[@]:-}" | awk 'NF' | awk '!seen[$0]++' | paste -sd, -)

if [ -n "$unique_labels" ]; then
  echo "Adding labels to PR #$NUMBER: $unique_labels"
  gh pr edit "$NUMBER" --add-label "$unique_labels"
else
  echo "No labels to add for PR #$NUMBER"
fi
```

### Fish CLI Automation Snippet

The same logic implemented for Fish shell.

```fish
#!/usr/bin/env fish
# Requires: gh, jq

# Fetch current PR metadata
set TITLE (gh pr view --json title --jq .title)
set AUTHOR (gh pr view --json author --jq .author.login)
set BRANCH (gh pr view --json headRefName --jq .headRefName)
set NUMBER (gh pr view --json number --jq .number)

set labels

# Map Conventional Commit type ‚Üí label
set TYPE (printf '%s' "$TITLE" | sed -E 's/^([a-zA-Z!]+)(\(.+\))?:.*/\1/' | tr 'A-Z' 'a-z' | sed 's/!$//')
switch "$TYPE"
case feat
  set labels $labels enhancement
case fix
  set labels $labels bug
case docs
  set labels $labels documentation
end

# Dependencies-related labels
if printf '%s' "$TITLE" | grep -qiE '^chore\(deps\)|^build\(deps\)|\bdeps\b|\bdependency\b'
  set labels $labels dependencies
end

# Bot-specific labels
if printf '%s' "$AUTHOR" | grep -qi '^dependabot'
  set labels $labels dependabot
end
if printf '%s' "$AUTHOR" | grep -qi '^renovate'
  set labels $labels renovate
end

# Auto-merge request detection
if printf '%s' "$TITLE" | grep -qi '\[automerge\]'
  set labels $labels automerge
end
if gh pr view --json body --jq .body | grep -qiE '^labels?:.*automerge'
  set labels $labels automerge
end

# De-duplicate labels
set unique_labels (printf '%s\n' $labels | awk 'NF' | awk '!seen[$0]++' | paste -sd, -)

if test -n "$unique_labels"
  echo "Adding labels to PR #$NUMBER: $unique_labels"
  gh pr edit "$NUMBER" --add-label "$unique_labels"
else
  echo "No labels to add for PR #$NUMBER"
end
```

## Usage

- Run the snippet after creating the PR, or integrate it into your local automation.
- Ensure the label names exist in the repository (they are provisioned via Pulumi from `labels.ts`).

## Maintenance

- If you change labels in `labels.ts`, update the list above and (optionally) extend the mapping.
- Keep mappings minimal to avoid mislabeling; prefer explicit over implicit where uncertain.

---
Source: .ruler/shell-usage.md
---
# Shell Usage Standard (Fish)

This repository uses the Fish shell for interactive commands and automation snippets, aligned with the system configuration. Prefer Fish for new scripts and examples.

## Policy
- Default shell: Fish (`#!/usr/bin/env fish`).
- Provide Fish snippets for automation examples; keep Bash as optional fallback when helpful.
- Keep one-file, shell-agnostic command sequences unchanged when they work in both shells.

## Conventions
- Variables: `set NAME value` (no `=`). Export: `set -x NAME value`.
- Arrays/lists: `set items a b c`; append: `set items $items d`.
- Conditionals: `if test -f file; ...; end`; switches: `switch $var; case value; ...; end`.
- Substitution: `set VAR (command ...)`.
- PATH: `set -x PATH /new/bin $PATH`.

## Shebangs
- Use `#!/usr/bin/env fish` for executable scripts.

## Compatibility Notes
- Avoid `set -euo pipefail`; Fish handles errors differently. Use explicit checks or `status` as needed.
- When porting Bash snippets, verify quoting and list handling.

---
Source: .ruler/tmp.linear-labeling.md
---
# Linear Issue Labeling & Assignment Rules

This rule standardizes Linear issue creation by auto-assigning to `shunkakinoki` and applying capitalized default labels sourced from `devops/infra/github/src/labels.ts`.

## Default Labels (capitalized)

- Bug
- Documentation
- Duplicate
- Enhancement
- Good First Issue
- Help Wanted
- Invalid
- Question
- Wontfix
- Dependabot
- Renovate
- Dependencies
- Automerge

Notes:
- Capitalization follows first-letter uppercase for each word.
- The source `labels.ts` contains lowercase names; apply capitalization at creation time.

## Assignment

- All newly created issues should be assigned to `shunkakinoki` by default.

---
Source: .ruler/tool-search.md
---
# Tool Search Guidelines

This document defines the preferred tools and methodologies for searching and analyzing code within the repository. These tools are optimized for different types of search tasks and should be used according to the patterns outlined below.

## Core Search Tools

### File Discovery
- **Primary**: `fd` - Fast and user-friendly alternative to `find`
  - Search for files by name, extension, or pattern
  - Respects `.gitignore` by default
  - Examples: `fd config.json`, `fd '*.ts'`, `fd -e md`

### Text Search
- **Primary**: `rg` (ripgrep) - High-performance text search
  - Full-text search across files
  - Regular expression support
  - Context options (`-A`, `-B`, `-C` for lines after/before/around matches)
  - Examples: `rg "function.*export"`, `rg -i "todo" -A 3`

### Code Structure Analysis
- **Primary**: `ast-grep` - AST-based code search and analysis
  - **Default to TypeScript contexts** for this codebase
  - Language-specific parsing for accurate structural matches
  - Pattern-based matching using AST nodes rather than text

#### Language Mapping for ast-grep:
- **TypeScript files** (`.ts`): `ast-grep --lang ts -p '<pattern>'`
- **React/TSX files** (`.tsx`): `ast-grep --lang tsx -p '<pattern>'`
- **JavaScript files** (`.js`, `.mjs`): `ast-grep --lang javascript -p '<pattern>'`
- **Rust files** (`.rs`): `ast-grep --lang rust -p '<pattern>'`
- **Python files** (`.py`): `ast-grep --lang python -p '<pattern>'`
- **Go files** (`.go`): `ast-grep --lang go -p '<pattern>'`

#### When to Use ast-grep Over Text Search:
- Finding function definitions, class declarations, or specific code patterns
- Refactoring operations that require understanding code structure
- Type-aware searches (finding usages of specific types, interfaces, etc.)
- Complex code transformations
- Avoiding false positives from comments or strings

#### ast-grep Pattern Examples:
```bash
# Find all function declarations
ast-grep --lang ts -p 'function $NAME($ARGS) { $$$ }'

# Find React components with specific props
ast-grep --lang tsx -p '<$COMP $PROPS>$$$</$COMP>'

# Find class methods
ast-grep --lang ts -p 'class $CLASS { $METHOD($ARGS) { $$$ } }'
```

### Interactive Selection
- **Primary**: `fzf` - Fuzzy finder for interactive selection
  - Pipe search results through fzf for interactive filtering
  - Examples: `fd '*.ts' | fzf`, `rg -l "export" | fzf`

### Data Processing
- **JSON**: `jq` - Command-line JSON processor
  - Parse, filter, and transform JSON data
  - Examples: `cat package.json | jq '.dependencies'`

- **YAML/XML**: `yq` - YAML/XML processor (similar to jq)
  - Handle YAML and XML files with jq-like syntax
  - Examples: `cat config.yaml | yq '.database.host'`

## Tool Selection Decision Tree

### 1. Code Structure Search
- **Use ast-grep when:**
  - Searching for specific code patterns (functions, classes, imports)
  - Need to understand code semantics, not just text matches
  - Working with TypeScript/JavaScript code (most common in this repo)
  - Performing refactoring or code transformation tasks
  - Need to avoid false positives from comments or string literals

### 2. Plain Text Search
- **Use ripgrep (rg) when:**
  - Searching for plain text content (documentation, comments, logs)
  - Simple string matching across multiple files
  - Need contextual lines around matches
  - Working with non-code files (markdown, configuration, etc.)
  - ast-grep doesn't support the target language

### 3. File Discovery
- **Use fd when:**
  - Finding files by name patterns
  - Listing files by extension
  - Exploring directory structures
  - Building file lists for further processing

## Best Practices

### Performance Optimization
- **Combine tools efficiently**: `fd '*.ts' | xargs ast-grep --lang ts -p 'pattern'`
- **Use appropriate scoping**: Limit searches to relevant directories when possible
- **Leverage caching**: Tools like `fd` and `rg` are already optimized for speed

### Accuracy and Precision
- **Prefer structural over textual**: Use ast-grep for code analysis, rg for content search
- **Validate language detection**: Ensure ast-grep uses the correct `--lang` parameter
- **Test patterns incrementally**: Start with simple patterns and refine as needed

### Integration Workflows
```bash
# Example: Find all TypeScript files with export statements, then select interactively
fd '*.ts' | xargs ast-grep --lang ts -l -p 'export $$$' | fzf

# Example: Search for TODO comments and show context
rg -i "todo|fixme" -C 2 --type typescript

# Example: Find and process configuration files
fd 'config.*\.json' | xargs jq '.version' | sort -u
```

### Error Handling
- **Fallback strategy**: If ast-grep fails or language is unsupported, fall back to rg
- **Validate tool availability**: Check tool installation before usage
- **Handle edge cases**: Account for mixed-language files and unusual extensions

## Tool Installation Verification

Before using these tools in scripts or automation:

```bash
# Check tool availability
command -v fd >/dev/null 2>&1 || { echo "fd not installed"; exit 1; }
command -v rg >/dev/null 2>&1 || { echo "ripgrep not installed"; exit 1; }
command -v ast-grep >/dev/null 2>&1 || { echo "ast-grep not installed"; exit 1; }
command -v fzf >/dev/null 2>&1 || { echo "fzf not installed"; exit 1; }
```

## Additional Tools

While the core tools above cover most use cases, these additional tools may be useful for specialized tasks:

- **`grep`**: Fallback for basic text search when rg is unavailable
- **`find`**: Fallback for file discovery when fd is unavailable  
- **`sed`/`awk`**: Text processing and transformation
- **`sort`/`uniq`**: Result deduplication and sorting
- **`xargs`**: Efficient command chaining for large result sets

## Repository-Specific Considerations

Given this repository's focus on TypeScript/JavaScript development:
- **Default to TypeScript context** when using ast-grep
- **Prioritize structural search** for code analysis tasks
- **Use ripgrep for documentation** and configuration file searches
- **Combine tools effectively** for complex search workflows

This tool selection strategy ensures efficient, accurate, and maintainable search operations across the entire codebase.

---
Source: .ruler/workspace-file-references.md
---
# Workspace File Reference Rule

## Overview

This rule governs how workspace files (such as `.code-workspace` files) should reference directories and paths.

## Rule

**DO NOT** refer to the rules directory (`../rules` or similar) in workspace files. The rules directory is for reference only and should not be included as a workspace folder.

Instead, use the current directory path with "." (e.g., `"."`) or reference the appropriate workspace/directory directly.

## Examples

### Incorrect:
```json
{
  "folders": [
    {
      "name": "rules",
      "path": "../rules"
    }
  ]
}
```

### Correct:
```json
{
  "folders": [
    {
      "name": "dotfiles",
      "path": "."
    }
  ]
}
```

## Rationale

The rules directory contains configuration and reference materials that should not be part of the active workspace. Including it can cause confusion and unnecessary clutter in the workspace structure.
