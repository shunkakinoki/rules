---
alwaysApply: true
---
---
Source: .ruler/commands.md
---
@commands
- [/commit-lint](commands/commit-lint.md) ‚Äî
- [/commit-push](commands/commit-push.md) ‚Äî
- [/issue-create](commands/issue-create.md) ‚Äî
- [/pr-create](commands/pr-create.md) ‚Äî
- [/pr-label](commands/pr-label.md) ‚Äî
- [/repo-setup](commands/repo-setup.md) ‚Äî
- [/ruler-apply](commands/ruler-apply.md) ‚Äî
- [/serena](commands/serena.md) ‚Äî Token-efficient Serena MCP command for structured app development and problem-solving

---
Source: .ruler/commit-lint.md
---
# /commit-lint ‚Äî Commit linting configuration for AI agents

This document outlines the commit linting configuration and guidelines that AI agents must follow when committing files.

## Overview

The commit linting system ensures code quality and consistency by automatically running formatting, linting, and commit message validation checks before any commits are made by AI agents. This comprehensive system uses both lefthook pre-commit hooks and commitlint to prevent the introduction of poorly formatted code or improperly formatted commit messages into the repository.

## Installation

### Commitlint Setup

Install commitlint for commit message validation:

```bash
# Install commitlint CLI and conventional config
pnpm add -D @commitlint/cli @commitlint/config-conventional

# Install lefthook for pre-commit hooks
pnpm add -D lefthook

# Initialize lefthook hooks
pnpm run lefthook:install
```

### Required Dependencies

Ensure these packages are installed:
- `@commitlint/cli` - Commit message linting
- `@commitlint/config-conventional` - Conventional commit rules
- `lefthook` - Git hooks management
- `@biomejs/biome` - Code formatting and linting

## Configuration

### Ruler.toml Configuration

The commit linting configuration is defined in `ruler.toml` under the `[commit]` section:

```toml
[commit]
enabled = true
pre_commit_commands = [
  "pnpm run format",    # Format code with Biome
  "pnpm run lint",      # Run linting and checks
  "pnpm run check"      # Run all quality checks
]
```

### Commitlint Configuration

Commit message validation is configured in `.commitlintrc.json`:

```json
{
  "extends": ["@commitlint/config-conventional"],
  "rules": {
    "type-enum": [
      2,
      "always",
      [
        "feat",
        "fix",
        "docs",
        "style",
        "refactor",
        "test",
        "chore",
        "perf",
        "ci",
        "build",
        "revert"
      ]
    ],
    "type-case": [2, "always", "lower"],
    "type-empty": [2, "never"],
    "subject-empty": [2, "never"],
    "subject-full-stop": [2, "never", "."],
    "header-max-length": [2, "always", 72],
    "body-leading-blank": [1, "always"],
    "footer-leading-blank": [1, "always"]
  }
}
```

### Lefthook Configuration

Git hooks are managed through `lefthook.yml` with three main stages:

1. **Pre-commit**: Code formatting and linting
2. **Commit-msg**: Commit message validation
3. **Pre-push**: Comprehensive quality checks

## Pre-commit Commands

### 1. Code Formatting (`pnpm run format`)
- Uses Biome to format all code files
- Ensures consistent indentation, spacing, and line breaks
- Applies project-specific formatting rules

### 2. Linting (`pnpm run lint`)
- Runs comprehensive linting checks
- Validates code quality and style
- Checks for potential bugs and issues

### 3. Quality Checks (`pnpm run check`)
- Runs all automated quality verification
- Ensures ruler rules are applied
- Verifies no uncommitted changes remain

## File Patterns

The linting system targets specific file types to optimize performance:

- **JavaScript/TypeScript**: `*.{js,jsx,ts,tsx}`
- **Configuration Files**: `*.{json,css,md,yml,yaml,toml}`
- **Programming Languages**: `*.py`, `*.rs`, `*.go`, `*.java`
- **Infrastructure**: `Makefile*`, `Dockerfile*`

## Auto-fix Capabilities

The system includes auto-fix commands that attempt to resolve issues automatically:

- **Biome Format**: `pnpm run biome:format`
  - Automatically formats code
  - Fixes spacing and indentation issues

- **Biome Check**: `pnpm run biome:check --write`
  - Auto-fixes linting violations where possible
  - Applies safe corrections

## Agent Responsibilities

When contributing code, AI agents must ensure code quality by:

1. **Run Pre-commit Checks**: Execute all pre-commit commands before finalizing changes
2. **Review Auto-fixes**: Verify that auto-fixes have been applied correctly
3. **Manual Fixes**: Address any issues that cannot be auto-fixed
4. **Verify Quality**: Ensure all checks pass before contributing
5. **Test Changes**: Validate that formatting changes don't break functionality
6. **Solo Authorship**: DO NOT include co-authorship in commit messages - commits should be solo-authored
7. **PR Attribution**: Include AI attribution in PR descriptions, not commit messages

## Pre-commit Hook Detection

AI agents must automatically detect which pre-commit hook system is being used and adapt their behavior accordingly:

### Detection Logic

```bash
# Check for lefthook
if [ -f ".lefthook.yml" ] || [ -f "lefthook.yml" ]; then
  HOOK_SYSTEM="lefthook"
elif [ -f ".pre-commit-config.yaml" ]; then
  HOOK_SYSTEM="pre-commit"
else
  HOOK_SYSTEM="none"
fi
```

#### Fish Detection Logic

```fish
# Check for lefthook (Fish)
set HOOK_SYSTEM none
if test -f .lefthook.yml -o -f lefthook.yml
  set HOOK_SYSTEM lefthook
else if test -f .pre-commit-config.yaml
  set HOOK_SYSTEM pre-commit
end
```

### Lefthook Detection and Usage

**Files to check:**
- `lefthook.yml` (project root)
- `.lefthook.yml` (project root)

**When lefthook is detected:**
- Use lefthook commands for validation
- Respect lefthook configuration settings
- Allow lefthook to handle pre-commit, commit-msg, and pre-push hooks
- Do not run duplicate linting if lefthook is configured

**Lefthook workflow:**
```bash
# Let lefthook handle the hooks automatically
git add <files>
git commit -m "feat: add new feature"

# lefthook will automatically run:
# - pre-commit: formatting and linting
# - commit-msg: commitlint validation
# - pre-push: comprehensive checks
```

### Pre-commit Detection and Usage

**Files to check:**
- `.pre-commit-config.yaml` (project root)

**When pre-commit is detected:**
- Use pre-commit commands for validation
- Respect pre-commit configuration
- Allow pre-commit to manage all hooks
- Do not interfere with pre-commit's hook management

**Pre-commit workflow:**
```bash
# Let pre-commit handle the hooks automatically
git add <files>
git commit -m "feat: add new feature"

# pre-commit will automatically run configured hooks
```

### No Hook System Detected

**When neither system is detected:**
- Fall back to manual validation
- Run linting commands directly
- Validate commit messages manually
- Provide guidance for setting up hooks

**Manual workflow:**
```bash
# Run manual checks
pnpm run lint
pnpm run format
pnpm run check

# Validate commit message format
echo "feat: add new feature" | npx commitlint

# Then commit
git add <files>
git commit -m "feat: add new feature"
```

### Agent Decision Flow

The agent should follow this decision-making process:

```mermaid
graph TD
    A[Agent starts commit process] --> B{Check for lefthook.yml}
    B -->|Found| C[Use lefthook workflow]
    B -->|Not found| D{Check for .pre-commit-config.yaml}
    D -->|Found| E[Use pre-commit workflow]
    D -->|Not found| F[Use manual validation workflow]

    C --> G[Let lefthook handle all hooks]
    E --> H[Let pre-commit handle all hooks]
    F --> I[Run manual checks and validation]

    G --> J[Commit with confidence]
    H --> J
    I --> J
```

### Conflict Resolution

**If both systems are detected:**
- Prioritize lefthook (more project-specific configuration)
- Warn about potential conflicts
- Suggest consolidating to one system

**Detection priority:**
1. lefthook (project-specific, more flexible)
2. pre-commit (standardized, widely adopted)
3. manual validation (fallback)

### Environment-Specific Behavior

**CI/CD Environment:**
- Always use manual validation
- Run all checks explicitly
- Don't rely on git hooks

**Local Development:**
- Use detected hook system
- Fall back to manual if hooks fail
- Provide helpful error messages

### Implementation Example

Here's how an AI agent can implement the detection logic:

```javascript
// Node.js/TypeScript implementation
function detectHookSystem(projectRoot = process.cwd()) {
  const fs = require('fs');
  const path = require('path');

  // Check for lefthook configuration
  const lefthookFiles = ['lefthook.yml', '.lefthook.yml'];
  for (const file of lefthookFiles) {
    if (fs.existsSync(path.join(projectRoot, file))) {
      return {
        system: 'lefthook',
        configFile: file,
        workflow: 'automatic'
      };
    }
  }

  // Check for pre-commit configuration
  const preCommitFile = '.pre-commit-config.yaml';
  if (fs.existsSync(path.join(projectRoot, preCommitFile))) {
    return {
      system: 'pre-commit',
      configFile: preCommitFile,
      workflow: 'automatic'
    };
  }

  // No hook system detected
  return {
    system: 'manual',
    configFile: null,
    workflow: 'manual'
  };
}

// Usage in agent
const hookConfig = detectHookSystem();

switch (hookConfig.system) {
  case 'lefthook':
    console.log(`‚úÖ Lefthook detected (${hookConfig.configFile})`);
    console.log('Using lefthook workflow...');
    break;

  case 'pre-commit':
    console.log(`‚úÖ Pre-commit detected (${hookConfig.configFile})`);
    console.log('Using pre-commit workflow...');
    break;

  default:
    console.log('‚ö†Ô∏è  No hook system detected');
    console.log('Using manual validation workflow...');
    break;
}
```

```python
# Python implementation
import os
from pathlib import Path

def detect_hook_system(project_root: str = ".") -> dict:
    """Detect which pre-commit hook system is being used."""

    # Check for lefthook configuration
    lefthook_files = ['lefthook.yml', '.lefthook.yml']
    for file in lefthook_files:
        if os.path.exists(os.path.join(project_root, file)):
            return {
                'system': 'lefthook',
                'config_file': file,
                'workflow': 'automatic'
            }

    # Check for pre-commit configuration
    pre_commit_file = '.pre-commit-config.yaml'
    if os.path.exists(os.path.join(project_root, pre_commit_file)):
        return {
            'system': 'pre-commit',
            'config_file': pre_commit_file,
            'workflow': 'automatic'
        }

    # No hook system detected
    return {
        'system': 'manual',
        'config_file': None,
        'workflow': 'manual'
    }

# Usage
hook_config = detect_hook_system()

if hook_config['system'] == 'lefthook':
    print(f"‚úÖ Lefthook detected ({hook_config['config_file']})")
    print("Using lefthook workflow...")
elif hook_config['system'] == 'pre-commit':
    print(f"‚úÖ Pre-commit detected ({hook_config['config_file']})")
    print("Using pre-commit workflow...")
else:
    print("‚ö†Ô∏è  No hook system detected")
    print("Using manual validation workflow...")
```

## Integration with Existing Tools

### Lefthook Integration
The commit linting system works alongside existing lefthook pre-commit hooks:

- **Pre-commit Hook**: Runs formatting on relevant files
- **Pre-push Hook**: Runs linting before pushing
- **Commit Lint**: Additional validation for AI agent commits

### Biome Configuration
The system leverages the existing Biome configuration:

```json
{
  "formatter": {
    "enabled": true,
    "formatWithErrors": true,
    "indentStyle": "space"
  },
  "linter": {
    "enabled": true,
    "rules": {
      "recommended": true
    }
  }
}
```

## Error Handling

### Common Issues
- **Formatting Failures**: Check Biome configuration and file permissions
- **Linting Errors**: Review error messages and fix manually if auto-fix fails
- **Command Not Found**: Ensure pnpm and Biome are properly installed

### Troubleshooting Steps
1. Verify Biome installation: `pnpm biome --version`
2. Check configuration: `pnpm run biome:check`
3. Run manual format: `pnpm run biome:format`
4. Review git status after fixes

## Quality Standards

### Code Formatting
- Use 2-space indentation (configured in Biome)
- Consistent line endings and encoding
- Proper spacing around operators and keywords

### Linting Rules
- Follow Biome recommended rules
- No unused variables or imports
- Consistent naming conventions
- Proper error handling

### Commit Message Standards
- Use conventional commit format: `feat:`, `fix:`, `refactor:`, `docs:`, `chore:`
- Keep messages under 72 characters
- Include descriptive details for complex changes

## Best Practices

### For AI Agents
- **Always run linting before contributing code**
- **Review auto-fixes for correctness**
- **Test functionality after formatting changes**
- **Use descriptive commit messages**
- **Solo-authored commits only** - DO NOT include co-authorship in commit messages
- **PR attribution only** - Include AI attribution in PR descriptions, not commits

### For Development Workflow
- **Regular updates**: Keep Biome and dependencies updated
- **Configuration review**: Regularly audit linting rules
- **Performance monitoring**: Ensure linting doesn't slow down workflow
- **Documentation updates**: Keep this document current with configuration changes

## Commit Message Standards

### Conventional Commit Format

All commit messages must follow the conventional commit format:

```bash
<type>[optional scope]: <description>

[optional body]

[optional footer]
```

### Commit Types

- `feat`: A new feature
- `fix`: A bug fix
- `docs`: Documentation only changes
- `style`: Changes that do not affect the meaning of the code
- `refactor`: A code change that neither fixes a bug nor adds a feature
- `test`: Adding missing tests or correcting existing tests
- `chore`: Changes to the build process or auxiliary tools
- `perf`: A code change that improves performance
- `ci`: Changes to CI configuration files and scripts
- `build`: Changes that affect the build system or external dependencies
- `revert`: Reverts a previous commit

### Examples

```bash
# Feature commit
feat: add user authentication system

# Bug fix with scope
fix(auth): resolve login validation error

# Documentation update
docs: update API documentation for v2.0

# Refactoring with body
refactor: simplify user model validation logic

- Remove redundant validation checks
- Consolidate error handling
- Improve code readability

# Breaking change
feat!: change authentication API interface

BREAKING CHANGE: The authenticate() method now requires email parameter
```


This commit linting system ensures that all AI agent contributions maintain the same high standards of code quality, formatting, and commit message conventions as human developers, creating a consistent and maintainable codebase.

---
Source: .ruler/commit-push.md
---
# /commit-push ‚Äî Conventional commit and push workflow

Use this command when committing changes to follow Conventional Commits standards and push with upstream tracking.

## Prerequisites
- Ensure all changes are staged or ready to be staged
- Work from a feature branch (not main)
- Run pre-commit checks before staging files
- Review and apply any auto-fixes

## Quick Workflow
```bash
# Stage all changes
git add .

# Or stage specific files
git add <file1> <file2>

# Commit with conventional format
git commit -m "feat: add new feature description"

# Push with upstream tracking (first push only)
git push -u origin <branch-name>

# Subsequent pushes (no -u needed)
git push
```

## Pre-commit Quality Checks

Before committing, ensure code quality by running:

```bash
# Run formatting with Biome
pnpm run format

# Run linting and checks
pnpm run lint

# Run all quality checks
pnpm run check
```

### Auto-fix Capabilities
The system includes auto-fix commands:

- **Biome Format**: `pnpm run biome:format` - Automatically formats code
- **Biome Check**: `pnpm run biome:check --write` - Auto-fixes linting violations

### Quality Verification
- **Review auto-fixes** for correctness before committing
- **Test changes** to ensure formatting doesn't break functionality
- **Verify all checks pass** before finalizing the commit

## Conventional Commit Types

- `feat:` - A new feature
- `fix:` - A bug fix
- `docs:` - Documentation only changes
- `style:` - Changes that do not affect the meaning of the code
- `refactor:` - A code change that neither fixes a bug nor adds a feature
- `test:` - Adding missing tests or correcting existing tests
- `chore:` - Changes to the build process or auxiliary tools
- `perf:` - A code change that improves performance
- `ci:` - Changes to CI configuration files and scripts
- `build:` - Changes that affect the build system or external dependencies
- `revert:` - Reverts a previous commit

## Commit Message Format

```bash
<type>[optional scope]: <description>

[optional body]

[optional footer]
```

### Examples

```bash
# Feature commit
feat: add user authentication system

# Bug fix with scope
fix(auth): resolve login validation error

# Documentation update
docs: update API documentation for v2.0

# Breaking change
feat!: change authentication API interface

BREAKING CHANGE: The authenticate() method now requires email parameter
```

## Interactive Commit Helper

For complex changes, use interactive staging:

```bash
# Interactive staging
git add -p

# Or use git gui for visual staging
git gui

# Then commit
git commit -m "feat: implement user dashboard"
```

## Branch Management

```bash
# Create and switch to new feature branch
git checkout -b feature/new-feature

# Push and set upstream (first time)
git push -u origin feature/new-feature

# Check branch status
git status
git branch -v
```

## Best Practices

- **Keep commits atomic**: Each commit should represent one logical change
- **Write clear descriptions**: Explain what changed and why
- **Stay under 72 characters**: For both title and body lines
- **Use present tense**: "Add feature" not "Added feature"
- **Reference issues**: Use `Closes #123` or `Fixes #456` in commit body
- **No co-authors in commits**: Keep commits solo-authored (per project policy)

## Troubleshooting

### Amend last commit
```bash
# Amend commit message
git commit --amend -m "feat: updated commit message"

# Amend and add more changes
git add <new-files>
git commit --amend --no-edit
```

### Undo last commit (keep changes)
```bash
git reset --soft HEAD~1
```

### Undo last commit (discard changes)
```bash
git reset --hard HEAD~1
```

### Fix commit message issues
```bash
# If commit message fails validation
git commit --amend
# Edit the message in your editor
# Save and exit

# Or amend with new message directly
git commit --amend -m "fix: correct validation logic"
```

## Integration with PR Workflow

After committing and pushing:
1. Use `/pr-create` command to create pull request
2. Follow PR creation checklist
3. Request reviewers as needed

## Reference
- Full commit linting rules: `/commit-lint`
- Pre-commit hook detection: `.ruler/commit-lint.md`
- PR creation workflow: `/pr-create`

---
Source: .ruler/issue-create.md
---
# /issue-create ‚Äî Standard Linear issue checklist

Follow this command to create Linear issues that align with the project's default assignment and labeling rules.

## Default Assignment
- Assign every new issue to `shunkakinoki` immediately after creation.
- Mention additional collaborators in the description instead of reassigning unless ownership genuinely changes.

## Labeling Rules
Apply capitalised labels sourced from `devops/infra/github/src/labels.ts`:
- Bug
- Documentation
- Duplicate
- Enhancement
- Good First Issue
- Help Wanted
- Invalid
- Question
- Wontfix
- Dependabot
- Renovate
- Dependencies
- Automerge

Add the most relevant primary label (e.g., `Enhancement` for features, `Bug` for fixes) and append `Dependencies`, `Automerge`, or automation labels only when they truly apply.

## Issue Body Guidelines
1. **Problem statement** ‚Äî Describe the user-facing impact or goal.
2. **Acceptance criteria** ‚Äî Bullet list of conditions that must be met.
3. **Technical notes** ‚Äî Implementation hints, links to specs, or affected services.
4. **Testing plan** ‚Äî Outline manual or automated validation steps.

## Tips
- Use templates where available, but still confirm assignment and labels afterwards.
- Cross-link related GitHub issues or PRs inline to give downstream automation the right context.
- Close the issue (or move to Done) only after verifying acceptance criteria and closing PRs that reference it.

---
Source: .ruler/pr-create.md
---
# /pr-create ‚Äî Comprehensive PR creation workflow

Use this command when preparing a pull request. Follow each section before running `gh pr create`.

## Prerequisites

### GitHub CLI Setup
- **Install GitHub CLI**: `which gh` (install if not found)
- **Verify authentication**: `gh auth status`
- **Required token scope**: Token must have `repo` scope for PR creation
- **Authentication**: Run `gh auth login` if not authenticated

### Branch Requirements
- **Work on feature branches** (never commit directly to `main`)
- **Keep branches focused** on single features/fixes
- **Use descriptive names** (e.g., `fix-build-dependencies`, `feat-user-auth`)
- **Current branch check**: `git branch --show-current`

## Complete Workflow

### Step 1: Prepare Changes
```bash
# Check current status and see what files changed
git status

# Stage specific files or all changes
git add <files>          # Stage specific files
git add .               # Stage all changes in current directory

# Or use interactive staging for complex changes
git add -p              # Interactive patch staging
```

### Step 2: Create Feature Branch (if needed)
```bash
# Create and switch to new feature branch
git checkout -b feature/new-feature-name

# Or switch to existing feature branch
git checkout existing-feature-branch

# Verify you're on the correct branch
git branch --show-current
```

### Step 3: Commit Changes
```bash
# Commit with conventional commit format
git commit -m "feat: add user authentication system

- Add login form component
- Implement JWT token handling
- Add user session management

Closes #123"

# Or use /commit-and-push command for guided workflow
# Reference: /commit-and-push
```

### Step 4: Push Branch
```bash
# Push and set upstream (first time only)
git push -u origin feature-branch-name

# Subsequent pushes (no -u needed)
git push
```

### Step 5: Create PR via CLI
```bash
gh pr create \
  --title "feat: add user authentication system" \
  --body "## Changes Made
- Added login form component with validation
- Implemented JWT token handling and storage
- Added user session management utilities
- Updated routing to protect authenticated routes

## Technical Details
- Uses React hooks for state management
- Implements secure token storage in localStorage
- Adds middleware for route protection
- Follows existing component patterns and styling

## Testing
- Verified login/logout flow works correctly
- All pre-commit hooks pass (Biome formatting, linting)
- Component tests added for auth utilities
- Manual testing completed on all major browsers
- No breaking changes to existing functionality

ü§ñ Generated with <AI NAME>" \
  --base main \
  --head feature-branch-name
```

## PR Content Standards

### Title Format
- **Use conventional commit format**: `feat:`, `fix:`, `refactor:`, `docs:`, `chore:`
- **Keep under 72 characters** for optimal display
- **Be specific and actionable**: "Add user auth" vs "Update stuff"
- **Include scope if relevant**: `fix(auth): resolve login issue`

### Description Requirements
- **Changes Made**: Bullet list of what was modified
- **Technical Details**: Implementation specifics and rationale
- **Testing**: Verification steps and pre-commit status
- **AI Attribution**: `ü§ñ Generated with <AI NAME>` (current assistant)

### AI Attribution Guidelines
- **Current assistant**: Replace `<AI NAME>` with your AI assistant name
- **Format**: `ü§ñ Generated with <AI NAME>` (no co-authorship)
- **Placement**: At the end of PR description
- **Consistency**: Use same attribution across all generated content

## Labeling & Reviewers

### Automatic Labeling
After PR creation, add appropriate labels:
```bash
# Feature PR
gh pr edit <number> --add-label enhancement

# Bug fix PR
gh pr edit <number> --add-label bug

# Documentation PR
gh pr edit <number> --add-label documentation

# Dependencies PR
gh pr edit <number> --add-label dependencies
```

### Request Reviewers
```bash
# Add specific reviewers
gh pr edit <number> --add-reviewer username1,username2

# Add team reviewers
gh pr edit <number> --add-reviewer "@org/team-name"
```

## Error Handling

### Common Issues & Solutions
- **Authentication failed**: Run `gh auth login`
- **Branch not found**: Ensure branch is pushed to remote first
- **Permission denied**: Check repository access and token scopes
- **PR already exists**: Use `gh pr edit` to modify existing PR

### Troubleshooting Commands
```bash
# Check PR status
gh pr list

# View PR details
gh pr view <number>

# Update PR description
gh pr edit <number> --body "Updated description"

# Change PR title
gh pr edit <number> --title "Updated title"

# Close PR
gh pr close <number>
```

## Best Practices

### Commit Guidelines
- **Solo-authored commits only** - DO NOT include co-authorship in commit messages
- **Use present tense** in commit messages ("Add feature" not "Added feature")
- **Keep commits atomic** and focused on single changes
- **Reference issues** when applicable (`Closes #123`, `Fixes #456`)

### PR Size Management
- **Keep PRs focused** on single concerns or related changes
- **Split large changes** into multiple smaller PRs
- **Use draft PRs** for work-in-progress or incomplete features
- **Request reviews early** for complex changes to get feedback

### Quality Assurance
- **Ensure all pre-commit hooks pass** before creating PR
- **Run tests** before creating PR (`uv run pytest` for this project)
- **Verify code formatting** (Biome handles this automatically)
- **Check for breaking changes** and document them clearly
- **Test manually** for UI/UX changes

### CI/CD Integration
- **PRs automatically trigger** CI pipelines
- **Address failing checks** promptly (tests, linting, formatting)
- **Monitor CI status** and fix issues before requesting review
- **Document known limitations** if any checks are expected to fail

## Complete Example

```bash
# 1. Create feature branch
git checkout -b feat-add-user-auth

# 2. Make changes and stage
git add src/components/Auth/ src/utils/auth.ts
git status

# 3. Commit with conventional format
git commit -m "feat: implement user authentication system

- Add login/logout components with form validation
- Implement JWT token management and secure storage
- Create auth context for global state management
- Add protected route wrapper component

Closes #123"

# 4. Push to remote
git push -u origin feat-add-user-auth

# 5. Create PR with comprehensive description
gh pr create \
  --title "feat: implement user authentication system" \
  --body "## Changes Made
- Added complete user authentication flow with login/logout
- Implemented secure JWT token handling and storage
- Created React context for global auth state management
- Added protected route components for authenticated pages

## Technical Details
- Uses React hooks and context for state management
- Implements secure token storage with expiration handling
- Follows existing component architecture and styling patterns
- Includes proper error handling and loading states

## Testing
- All pre-commit hooks pass (Biome formatting, linting, TypeScript checks)
- Component tests added for auth utilities and context
- Manual testing completed for login/logout flows
- Verified compatibility with existing user management

ü§ñ Generated with <AI NAME>" \
  --base main \
  --head feat-add-user-auth

# 6. Add labels and reviewers
gh pr edit <pr-number> --add-label enhancement
gh pr edit <pr-number> --add-reviewer "@org/frontend-team"
```

## Integration with Other Commands

- **Commit workflow**: Use `/commit-and-push` for guided conventional commits
- **Code quality**: Reference `.ruler/commit-lint.md` for detailed standards
- **PR labeling**: Use `/pr-labeling` for automated label management

## Reference
- Full policy: `.ruler/pr-creation.md` in this repository
- Commit standards: `/commit-and-push`
- Labeling automation: `/pr-labeling`

---
Source: .ruler/pr-label.md
---
# /pr-label - Comprehensive PR Labeling Guide

This document outlines the rules and best practices for automatically labeling GitHub Pull Requests (PRs) based on Conventional Commit types and other criteria.

## GitHub PR Labeling Rules

This rule defines how PR labels are applied automatically. It uses the default labels and maps Conventional Commit types to GitHub labels.

## Default Labels (source of truth)

Names are defined as:

- bug
- documentation
- duplicate
- enhancement
- good first issue
- help wanted
- invalid
- question
- wontfix
- dependabot
- renovate
- dependencies
- automerge

## Label Mapping Rules

- feat ‚Üí enhancement
- fix ‚Üí bug
- docs ‚Üí documentation
- chore(deps), build(deps) ‚Üí dependencies
- PR authored by dependabot ‚Üí dependabot
- PR authored by renovate ‚Üí renovate
- If title contains "[automerge]" or label "automerge" is requested in the description, also add automerge

Notes:
- Only apply one of enhancement/bug/documentation based on the primary Conventional Commit type at the start of the PR title.
- Do not add unrelated labels automatically.

## Usage

- Run the snippet after creating the PR, or integrate it into your local automation.
- Ensure the label names exist in the repository (they are provisioned via Pulumi from `labels.ts`).

---
Source: .ruler/repo-setup.md
---
# /repo-setup ‚Äî Local environment bootstrap

This command bootstraps a fresh checkout so tooling and automated hooks run consistently across contributors.

## Prerequisites
- Node.js 18 or newer (matches the version required by Ruler)
- pnpm 9.15.4 (matches the `packageManager` field)
- Git with commit signing configured if your workflow requires it

## Installation Steps
```fish
# Install all workspace dependencies
pnpm install

# Install Git hooks managed by lefthook
pnpm run lefthook:install

# Generate and sync agent instructions via Ruler
pnpm run ruler:apply
```

## Verification
- Run `pnpm run check` to ensure Biome and Ruler checks pass without modifying files.
- Inspect `git status` and confirm there are no unexpected changes after the commands complete.
- Optionally run `pnpm run ruler:check` for a non-destructive confirmation that generated files stay in sync.

## Troubleshooting
- If pnpm is missing, install it with `corepack enable pnpm` or follow the [pnpm installation guide](https://pnpm.io/installation).
- When `pnpm run ruler:apply` updates tracked files, review and commit those changes so teammates stay aligned.
- If lefthook scripts fail, re-run `pnpm run lefthook:install` and verify your Git hooks directory has execute permissions.

---
Source: .ruler/ruler-apply.md
---
# /ruler-apply ‚Äî Regenerate agent instructions with Ruler

Use this command whenever `.ruler/` files or command documentation changes, or after pulling updates that touch repository rules.

## When to Run
- After editing any file under `.ruler/` (including `commands/` docs referenced from there)
- Before committing changes that rely on regenerated instruction files such as `AGENTS.md`
- After rebasing or pulling main when rules may have changed

## Command Sequence
```fish
# Regenerate agent instruction files
pnpm run ruler:apply

# Double-check that regeneration left the tree clean
pnpm run ruler:check
```

## What to Inspect
- Review `git status` for modified instruction outputs (e.g., `AGENTS.md`, `.cursor/...`).
- If files changed, skim the diff to ensure new content reflects your rule updates.
- Commit regenerated files together with the rule change so other contributors stay in sync.

## Troubleshooting
- If `pnpm run ruler:check` reports a dirty tree, run `git status --short` to see which files still differ.
- For merge conflicts in generated files, resolve them in the source `.ruler/` Markdown first, re-run `/ruler-apply`, then commit the regenerated outputs.
- When `.gitignore` changes unexpectedly, confirm `[gitignore].enabled` in `.ruler/ruler.toml` matches the desired setting before re-running the command.

---
Source: .ruler/shell-usage.md
---
# Shell Usage Standard (Fish)

This repository uses the Fish shell for interactive commands and automation snippets, aligned with the system configuration. Prefer Fish for new scripts and examples.

## Policy
- Default shell: Fish (`#!/usr/bin/env fish`).
- Provide Fish snippets for automation examples; keep Bash as optional fallback when helpful.
- Keep one-file, shell-agnostic command sequences unchanged when they work in both shells.

## Conventions
- Variables: `set NAME value` (no `=`). Export: `set -x NAME value`.
- Arrays/lists: `set items a b c`; append: `set items $items d`.
- Conditionals: `if test -f file; ...; end`; switches: `switch $var; case value; ...; end`.
- Substitution: `set VAR (command ...)`.
- PATH: `set -x PATH /new/bin $PATH`.

## Shebangs
- Use `#!/usr/bin/env fish` for executable scripts.

## Compatibility Notes
- Avoid `set -euo pipefail`; Fish handles errors differently. Use explicit checks or `status` as needed.
- When porting Bash snippets, verify quoting and list handling.

---
Source: .ruler/tmp.linear-labeling.md
---
# Linear Issue Labeling & Assignment Rules

This rule standardizes Linear issue creation by auto-assigning to `shunkakinoki` and applying capitalized default labels sourced from `devops/infra/github/src/labels.ts`.

## Default Labels (capitalized)

- Bug
- Documentation
- Duplicate
- Enhancement
- Good First Issue
- Help Wanted
- Invalid
- Question
- Wontfix
- Dependabot
- Renovate
- Dependencies
- Automerge

Notes:
- Capitalization follows first-letter uppercase for each word.
- The source `labels.ts` contains lowercase names; apply capitalization at creation time.

## Assignment

- All newly created issues should be assigned to `shunkakinoki` by default.

---
Source: .ruler/tool-search.md
---
# Tool Search Guidelines

This document defines the preferred tools and methodologies for searching and analyzing code within the repository. These tools are optimized for different types of search tasks and should be used according to the patterns outlined below.

## Core Search Tools

### File Discovery
- **Primary**: `fd` - Fast and user-friendly alternative to `find`
  - Search for files by name, extension, or pattern
  - Respects `.gitignore` by default
  - Examples: `fd config.json`, `fd '*.ts'`, `fd -e md`

### Text Search
- **Primary**: `rg` (ripgrep) - High-performance text search
  - Full-text search across files
  - Regular expression support
  - Context options (`-A`, `-B`, `-C` for lines after/before/around matches)
  - Examples: `rg "function.*export"`, `rg -i "todo" -A 3`

### Code Structure Analysis
- **Primary**: `ast-grep` - AST-based code search and analysis
  - **Default to TypeScript contexts** for this codebase
  - Language-specific parsing for accurate structural matches
  - Pattern-based matching using AST nodes rather than text

#### Language Mapping for ast-grep:
- **TypeScript files** (`.ts`): `ast-grep --lang ts -p '<pattern>'`
- **React/TSX files** (`.tsx`): `ast-grep --lang tsx -p '<pattern>'`
- **JavaScript files** (`.js`, `.mjs`): `ast-grep --lang javascript -p '<pattern>'`
- **Rust files** (`.rs`): `ast-grep --lang rust -p '<pattern>'`
- **Python files** (`.py`): `ast-grep --lang python -p '<pattern>'`
- **Go files** (`.go`): `ast-grep --lang go -p '<pattern>'`

#### When to Use ast-grep Over Text Search:
- Finding function definitions, class declarations, or specific code patterns
- Refactoring operations that require understanding code structure
- Type-aware searches (finding usages of specific types, interfaces, etc.)
- Complex code transformations
- Avoiding false positives from comments or strings

#### ast-grep Pattern Examples:
```bash
# Find all function declarations
ast-grep --lang ts -p 'function $NAME($ARGS) { $$$ }'

# Find React components with specific props
ast-grep --lang tsx -p '<$COMP $PROPS>$$$</$COMP>'

# Find class methods
ast-grep --lang ts -p 'class $CLASS { $METHOD($ARGS) { $$$ } }'
```

### Interactive Selection
- **Primary**: `fzf` - Fuzzy finder for interactive selection
  - Pipe search results through fzf for interactive filtering
  - Examples: `fd '*.ts' | fzf`, `rg -l "export" | fzf`

### Data Processing
- **JSON**: `jq` - Command-line JSON processor
  - Parse, filter, and transform JSON data
  - Examples: `cat package.json | jq '.dependencies'`

- **YAML/XML**: `yq` - YAML/XML processor (similar to jq)
  - Handle YAML and XML files with jq-like syntax
  - Examples: `cat config.yaml | yq '.database.host'`

## Tool Selection Decision Tree

### 1. Code Structure Search
- **Use ast-grep when:**
  - Searching for specific code patterns (functions, classes, imports)
  - Need to understand code semantics, not just text matches
  - Working with TypeScript/JavaScript code (most common in this repo)
  - Performing refactoring or code transformation tasks
  - Need to avoid false positives from comments or string literals

### 2. Plain Text Search
- **Use ripgrep (rg) when:**
  - Searching for plain text content (documentation, comments, logs)
  - Simple string matching across multiple files
  - Need contextual lines around matches
  - Working with non-code files (markdown, configuration, etc.)
  - ast-grep doesn't support the target language

### 3. File Discovery
- **Use fd when:**
  - Finding files by name patterns
  - Listing files by extension
  - Exploring directory structures
  - Building file lists for further processing

## Best Practices

### Performance Optimization
- **Combine tools efficiently**: `fd '*.ts' | xargs ast-grep --lang ts -p 'pattern'`
- **Use appropriate scoping**: Limit searches to relevant directories when possible
- **Leverage caching**: Tools like `fd` and `rg` are already optimized for speed

### Accuracy and Precision
- **Prefer structural over textual**: Use ast-grep for code analysis, rg for content search
- **Validate language detection**: Ensure ast-grep uses the correct `--lang` parameter
- **Test patterns incrementally**: Start with simple patterns and refine as needed

### Integration Workflows
```bash
# Example: Find all TypeScript files with export statements, then select interactively
fd '*.ts' | xargs ast-grep --lang ts -l -p 'export $$$' | fzf

# Example: Search for TODO comments and show context
rg -i "todo|fixme" -C 2 --type typescript

# Example: Find and process configuration files
fd 'config.*\.json' | xargs jq '.version' | sort -u
```

### Error Handling
- **Fallback strategy**: If ast-grep fails or language is unsupported, fall back to rg
- **Validate tool availability**: Check tool installation before usage
- **Handle edge cases**: Account for mixed-language files and unusual extensions

## Tool Installation Verification

Before using these tools in scripts or automation:

```bash
# Check tool availability
command -v fd >/dev/null 2>&1 || { echo "fd not installed"; exit 1; }
command -v rg >/dev/null 2>&1 || { echo "ripgrep not installed"; exit 1; }
command -v ast-grep >/dev/null 2>&1 || { echo "ast-grep not installed"; exit 1; }
command -v fzf >/dev/null 2>&1 || { echo "fzf not installed"; exit 1; }
```

## Additional Tools

While the core tools above cover most use cases, these additional tools may be useful for specialized tasks:

- **`grep`**: Fallback for basic text search when rg is unavailable
- **`find`**: Fallback for file discovery when fd is unavailable  
- **`sed`/`awk`**: Text processing and transformation
- **`sort`/`uniq`**: Result deduplication and sorting
- **`xargs`**: Efficient command chaining for large result sets

## Repository-Specific Considerations

Given this repository's focus on TypeScript/JavaScript development:
- **Default to TypeScript context** when using ast-grep
- **Prioritize structural search** for code analysis tasks
- **Use ripgrep for documentation** and configuration file searches
- **Combine tools effectively** for complex search workflows

This tool selection strategy ensures efficient, accurate, and maintainable search operations across the entire codebase.

---
Source: .ruler/workspace-file-references.md
---
# Workspace File Reference Rule

## Overview

This rule governs how workspace files (such as `.code-workspace` files) should reference directories and paths.

## Rule

**DO NOT** refer to the rules directory (`../rules` or similar) in workspace files. The rules directory is for reference only and should not be included as a workspace folder.

Instead, use the current directory path with "." (e.g., `"."`) or reference the appropriate workspace/directory directly.

## Examples

### Incorrect:
```json
{
  "folders": [
    {
      "name": "rules",
      "path": "../rules"
    }
  ]
}
```

### Correct:
```json
{
  "folders": [
    {
      "name": "dotfiles",
      "path": "."
    }
  ]
}
```

## Rationale

The rules directory contains configuration and reference materials that should not be part of the active workspace. Including it can cause confusion and unnecessary clutter in the workspace structure.
